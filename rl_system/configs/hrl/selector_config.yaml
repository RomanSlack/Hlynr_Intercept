# Selector Policy Training Configuration (Phase 1: Stub)
# High-level policy for option selection

# Inherit base settings
parent_config: ../../config.yaml

# Selector-specific training
training:
  total_timesteps: 50000  # Selector training steps (stub: minimal)
  n_envs: 4
  n_steps: 512

  # Learning parameters
  learning_rate: 0.0003
  gamma: 0.99
  gae_lambda: 0.95

  # Network architecture (smaller for discrete actions)
  net_arch: [256, 256]
  use_lstm: false
  frame_stack: 1  # Selector uses abstract state, no frame stacking

# HRL settings
hrl:
  enabled: true
  decision_interval_steps: 100
  # TODO(Phase 2): Freeze specialist policies during selector training
